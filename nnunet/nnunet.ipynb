{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nnU-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.3rc1+2.g7a8680e8\n",
      "Numpy version: 2.0.0\n",
      "Pytorch version: 2.3.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 7a8680e84457cb374859639ab6a078313da85926\n",
      "MONAI __file__: /home/<username>/miniforge3/envs/nnunet/lib/python3.11/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: 0.24.0\n",
      "scipy version: 1.14.0\n",
      "Pillow version: 10.4.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.18.1\n",
      "tqdm version: 4.66.4\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 6.0.0\n",
      "pandas version: 2.2.2\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import tempfile\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datalist Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup paths to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mark/GitHub/Project-MONAI-tutorials/monai_data_dir\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "if directory is not None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download sample MSD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd_task = \"Task09_Spleen\"\n",
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/\" + msd_task + \".tar\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, msd_task + \".tar\")\n",
    "dataroot = os.path.join(root_dir, msd_task)\n",
    "\n",
    "if not os.path.exists(dataroot):\n",
    "    download_and_extract(resource, compressed_file, root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSD dataset structure follows the following convention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(dataroot, \"imagesTs/\")\n",
    "train_dir = os.path.join(dataroot, \"imagesTr/\")\n",
    "label_dir = os.path.join(dataroot, \"labelsTr/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct skeleton JSON to populate with your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist_json = {\"testing\": [], \"training\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate JSON with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist_json[\"testing\"] = [\n",
    "    {\"image\": \"./imagesTs/\" + file} for file in os.listdir(test_dir) if (\".nii.gz\" in file) and (\"._\" not in file)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': './imagesTs/spleen_55.nii.gz'},\n",
       " {'image': './imagesTs/spleen_7.nii.gz'},\n",
       " {'image': './imagesTs/spleen_39.nii.gz'},\n",
       " {'image': './imagesTs/spleen_36.nii.gz'},\n",
       " {'image': './imagesTs/spleen_43.nii.gz'},\n",
       " {'image': './imagesTs/spleen_50.nii.gz'},\n",
       " {'image': './imagesTs/spleen_11.nii.gz'},\n",
       " {'image': './imagesTs/spleen_42.nii.gz'},\n",
       " {'image': './imagesTs/spleen_57.nii.gz'},\n",
       " {'image': './imagesTs/spleen_23.nii.gz'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalist_json[\"testing\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate with training images and labels in your directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist_json[\"training\"] = [\n",
    "    {\"image\": \"./imagesTr/\" + file, \"label\": \"./labelsTr/\" + file, \"fold\": 0}\n",
    "    for file in os.listdir(train_dir)\n",
    "    if (\".nii.gz\" in file) and (\"._\" not in file)\n",
    "]  # Initialize as single fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': './imagesTr/spleen_20.nii.gz',\n",
       "  'label': './labelsTr/spleen_20.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_12.nii.gz',\n",
       "  'label': './labelsTr/spleen_12.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_59.nii.gz',\n",
       "  'label': './labelsTr/spleen_59.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_8.nii.gz',\n",
       "  'label': './labelsTr/spleen_8.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_3.nii.gz',\n",
       "  'label': './labelsTr/spleen_3.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_26.nii.gz',\n",
       "  'label': './labelsTr/spleen_26.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_21.nii.gz',\n",
       "  'label': './labelsTr/spleen_21.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_13.nii.gz',\n",
       "  'label': './labelsTr/spleen_13.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_56.nii.gz',\n",
       "  'label': './labelsTr/spleen_56.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_52.nii.gz',\n",
       "  'label': './labelsTr/spleen_52.nii.gz',\n",
       "  'fold': 0}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalist_json[\"training\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomise training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': './imagesTr/spleen_52.nii.gz',\n",
       "  'label': './labelsTr/spleen_52.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_8.nii.gz',\n",
       "  'label': './labelsTr/spleen_8.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_46.nii.gz',\n",
       "  'label': './labelsTr/spleen_46.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_19.nii.gz',\n",
       "  'label': './labelsTr/spleen_19.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_10.nii.gz',\n",
       "  'label': './labelsTr/spleen_10.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_29.nii.gz',\n",
       "  'label': './labelsTr/spleen_29.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_45.nii.gz',\n",
       "  'label': './labelsTr/spleen_45.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_14.nii.gz',\n",
       "  'label': './labelsTr/spleen_14.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_3.nii.gz',\n",
       "  'label': './labelsTr/spleen_3.nii.gz',\n",
       "  'fold': 0},\n",
       " {'image': './imagesTr/spleen_38.nii.gz',\n",
       "  'label': './labelsTr/spleen_38.nii.gz',\n",
       "  'fold': 0}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(datalist_json[\"training\"])\n",
    "datalist_json[\"training\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training data into N random folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "fold_size = len(datalist_json[\"training\"]) // num_folds\n",
    "for i in range(num_folds):\n",
    "    for j in range(fold_size):\n",
    "        datalist_json[\"training\"][i * fold_size + j][\"fold\"] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise final training data with all randomised folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': './imagesTr/spleen_60.nii.gz',\n",
       "  'label': './labelsTr/spleen_60.nii.gz',\n",
       "  'fold': 3},\n",
       " {'image': './imagesTr/spleen_41.nii.gz',\n",
       "  'label': './labelsTr/spleen_41.nii.gz',\n",
       "  'fold': 3},\n",
       " {'image': './imagesTr/spleen_59.nii.gz',\n",
       "  'label': './labelsTr/spleen_59.nii.gz',\n",
       "  'fold': 3},\n",
       " {'image': './imagesTr/spleen_20.nii.gz',\n",
       "  'label': './labelsTr/spleen_20.nii.gz',\n",
       "  'fold': 3},\n",
       " {'image': './imagesTr/spleen_53.nii.gz',\n",
       "  'label': './labelsTr/spleen_53.nii.gz',\n",
       "  'fold': 3},\n",
       " {'image': './imagesTr/spleen_32.nii.gz',\n",
       "  'label': './labelsTr/spleen_32.nii.gz',\n",
       "  'fold': 3},\n",
       " {'image': './imagesTr/spleen_26.nii.gz',\n",
       "  'label': './labelsTr/spleen_26.nii.gz',\n",
       "  'fold': 4},\n",
       " {'image': './imagesTr/spleen_21.nii.gz',\n",
       "  'label': './labelsTr/spleen_21.nii.gz',\n",
       "  'fold': 4},\n",
       " {'image': './imagesTr/spleen_56.nii.gz',\n",
       "  'label': './labelsTr/spleen_56.nii.gz',\n",
       "  'fold': 4},\n",
       " {'image': './imagesTr/spleen_22.nii.gz',\n",
       "  'label': './labelsTr/spleen_22.nii.gz',\n",
       "  'fold': 4},\n",
       " {'image': './imagesTr/spleen_6.nii.gz',\n",
       "  'label': './labelsTr/spleen_6.nii.gz',\n",
       "  'fold': 4},\n",
       " {'image': './imagesTr/spleen_2.nii.gz',\n",
       "  'label': './labelsTr/spleen_2.nii.gz',\n",
       "  'fold': 4},\n",
       " {'image': './imagesTr/spleen_12.nii.gz',\n",
       "  'label': './labelsTr/spleen_12.nii.gz',\n",
       "  'fold': 4},\n",
       " {'image': './imagesTr/spleen_13.nii.gz',\n",
       "  'label': './labelsTr/spleen_13.nii.gz',\n",
       "  'fold': 4},\n",
       " {'image': './imagesTr/spleen_47.nii.gz',\n",
       "  'label': './labelsTr/spleen_47.nii.gz',\n",
       "  'fold': 0}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalist_json[\"training\"][-15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save JSON to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datalist is saved to msd_task09_spleen_folds.json\n"
     ]
    }
   ],
   "source": [
    "datalist_file = \"msd_\" + msd_task.lower() + \"_folds.json\"\n",
    "with open(datalist_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(datalist_json, f, ensure_ascii=False, indent=4)\n",
    "print(f\"Datalist is saved to {datalist_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with Minimal Input using `nnUNetV2Runner`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "After creating the data list, the user can create a simple \"input.yaml\" file (shown below) as the minimum input for **nnUNetV2Runner**.\n",
    "\n",
    "```yaml\n",
    "modality: CT\n",
    "datalist: \"./msd_task09_spleen_folds.json\"\n",
    "dataroot: \"/workspace/data/Task09_Spleen\"\n",
    "```\n",
    "\n",
    "Note: For multi-modal inputs, please check the **Frequently Asked Questions** section\n",
    "\n",
    "Users can also set values of directory variables as options in \"input.yaml\" if any directory needs to be specified.\n",
    "\n",
    "```yaml\n",
    "dataset_name_or_id: 1 # task-specific integer index (optional)\n",
    "nnunet_preprocessed: \"./work_dir/nnUNet_preprocessed\" # directory for storing pre-processed data (optional)\n",
    "nnunet_raw: \"./work_dir/nnUNet_raw_data_base\" # directory for storing formated raw data (optional)\n",
    "nnunet_results: \"./work_dir/nnUNet_trained_models\" # diretory for storing trained model checkpoints (optional)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once the minimum input information is provided, the user can use the following commands to start the process of the entire nnU-Net pipeline automatically (from model training to model ensemble).\n",
    "\n",
    "```bash\n",
    "python -m monai.apps.nnunet nnUNetV2Runner run --input_config='./input.yaml'\n",
    "```\n",
    "\n",
    "For experiment and debugging purposes, users may want to set the number of epochs of training in the nnU-Net pipeline.\n",
    "Our integration offers an optional argument `trainer_class_name` to specify the number of epochs as below:\n",
    "\n",
    "```bash\n",
    "python -m monai.apps.nnunet nnUNetV2Runner run --input_config='./input.yaml' --trainer_class_name nnUNetTrainer_1epoch\n",
    "```\n",
    "\n",
    "The supported `trainer_class_name` are:\n",
    "- nnUNetTrainer (default)\n",
    "- nnUNetTrainer_1epoch\n",
    "- nnUNetTrainer_5epochs\n",
    "- nnUNetTrainer_10epochs\n",
    "- nnUNetTrainer_20epochs\n",
    "- nnUNetTrainer_50epochs\n",
    "- nnUNetTrainer_100epochs\n",
    "- nnUNetTrainer_250epochs\n",
    "- nnUNetTrainer_2000epochs\n",
    "- nnUNetTrainer_4000epochs\n",
    "- nnUNetTrainer_8000epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:31:36,494 - WARNING - Dataset with name/ID: 9 cannot be found in the record. Please ignore the message above if you are running the pipeline from a fresh start. But if the dataset is expected to be found, please check your input_config.\n",
      "2024-07-22 21:31:40,449 - INFO - num_input_channels: 1\n",
      "2024-07-22 21:32:33,382 - INFO - num_foreground_classes: 1\n",
      "2024-07-22 21:32:33,382 - INFO - converting data section: training...\n",
      "100%|███████████████████████████████████████████| 41/41 [04:04<00:00,  5.95s/it]\n",
      "2024-07-22 21:36:37,533 - INFO - converting data section: testing...\n",
      "100%|███████████████████████████████████████████| 20/20 [01:17<00:00,  3.87s/it]\n"
     ]
    }
   ],
   "source": [
    "!python -m monai.apps.nnunet nnUNetV2Runner convert_dataset --input_config \"./input.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plan and process experiment using V2 plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:40:46,837 - INFO - Fingerprint extraction...\n",
      "Dataset009_Task09_Spleen\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "100%|███████████████████████████████████████████| 41/41 [00:05<00:00,  6.92it/s]\n",
      "2024-07-22 21:40:55,182 - INFO - Experiment planning...\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.60001004 0.81675806 0.81675806]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [187.         497.08737864 497.08737864]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.64801034 0.8412608  0.8412608 ]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [181.55339806 482.60910548 482.60910548]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.69745065 0.86649862 0.86649862]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [176.26543501 468.55252959 468.55252959]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.74837417 0.89249358 0.89249358]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [171.1314903  454.90536853 454.90536853]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.80082539 0.91926839 0.91926839]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [166.14707796 441.6556976  441.6556976 ]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.85485016 0.94684644 0.94684644]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [161.30784268 428.79193942 428.79193942]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.91049566 0.97525183 0.97525183]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [156.609556   416.30285381 416.30285381]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.96781053 1.00450939 1.00450939]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [152.04811262 404.17752797 404.17752797]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.02684485 1.03464467 1.03464467]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [147.61952682 392.40536696 392.40536696]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.08765019 1.06568401 1.06568401]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [143.31992895 380.97608443 380.97608443]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.1502797  1.09765453 1.09765453]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [139.14556209 369.87969362 369.87969362]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.21478809 1.13058417 1.13058417]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [135.09277872 359.10649866 359.10649866]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.28123173 1.16450169 1.16450169]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [131.1580376  348.64708608 348.64708608]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.34966868 1.19943674 1.19943674]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [127.33790058 338.49231658 338.49231658]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.42015874 1.23541985 1.23541985]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [123.62902969 328.63331707 328.63331707]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.4927635  1.27248244 1.27248244]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [120.02818416 319.06147288 319.06147288]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.56754641 1.31065691 1.31065691]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [116.53221763 309.76842027 309.76842027]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.6445728  1.34997662 1.34997662]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [113.13807537 300.7460391  300.7460391 ]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.72390999 1.39047592 1.39047592]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [109.84279162 291.98644573 291.98644573]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 13, 'patch_size': (np.int64(512), np.int64(512)), 'median_image_size_in_voxels': array([512., 512.]), 'spacing': array([0.79296899, 0.79296899]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "3D lowres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(64), np.int64(192), np.int64(192)), 'median_image_size_in_voxels': (110, 292, 292), 'spacing': array([2.72390999, 1.39047592, 1.39047592]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'}\n",
      "\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(64), np.int64(160), np.int64(160)), 'median_image_size_in_voxels': array([187., 512., 512.]), 'spacing': array([1.60001004, 0.79296899, 0.79296899]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((1, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (1, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Plans were saved to ./work_dir/nnUNet_preprocessed/Dataset009_Task09_Spleen/nnUNetPlans.json\n",
      "2024-07-22 21:41:10,455 - INFO - Preprocessing...\n",
      "Preprocessing dataset Dataset009_Task09_Spleen\n",
      "Configuration: 2d...\n",
      "100%|███████████████████████████████████████████| 41/41 [00:49<00:00,  1.22s/it]\n",
      "Configuration: 3d_fullres...\n",
      "100%|███████████████████████████████████████████| 41/41 [02:03<00:00,  3.02s/it]\n",
      "Configuration: 3d_lowres...\n",
      "100%|███████████████████████████████████████████| 41/41 [00:40<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "!python -m monai.apps.nnunet nnUNetV2Runner plan_and_process -pl nnUNetPlannerResEncM --input_config \"./input.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train all 20 models using all available GPU(s), specifying 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:54:04,235 - INFO - number of GPUs is 1, device ids are (0,)\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-07-22 21:54:06.727874: do_dummy_2d_data_aug: False\n",
      "2024-07-22 21:54:06.728213: Using splits from existing split file: ./work_dir/nnUNet_preprocessed/Dataset009_Task09_Spleen/splits_final.json\n",
      "2024-07-22 21:54:06.728369: The split file contains 5 splits.\n",
      "2024-07-22 21:54:06.728428: Desired fold for training: 0\n",
      "2024-07-22 21:54:06.728492: This split has 32 training and 9 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2024-07-22 21:54:16.546970: Using torch.compile...\n",
      "/home/mark/miniforge3/envs/nnunet/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [64, 160, 160], 'median_image_size_in_voxels': [187.0, 512.0, 512.0], 'spacing': [1.6000100374221802, 0.7929689884185791, 0.7929689884185791], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset009_Task09_Spleen', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.7929689884185791, 0.7929689884185791], 'original_median_shape_after_transp': [90, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1038.0, 'mean': 93.19261932373047, 'median': 97.0, 'min': -620.0, 'percentile_00_5': -42.0, 'percentile_99_5': 176.0, 'std': 40.78367614746094}}} \n",
      "\n",
      "2024-07-22 21:54:17.146265: unpacking dataset...\n",
      "2024-07-22 21:54:28.526206: unpacking done...\n",
      "2024-07-22 21:54:28.527483: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2024-07-22 21:54:28.537110: \n",
      "2024-07-22 21:54:28.537223: Epoch 0\n",
      "2024-07-22 21:54:28.537370: Current learning rate: 0.01\n",
      "2024-07-22 21:57:53.946844: train_loss -0.2134\n",
      "2024-07-22 21:57:53.947011: val_loss -0.4826\n",
      "2024-07-22 21:57:53.947103: Pseudo dice [np.float32(0.679)]\n",
      "2024-07-22 21:57:53.947197: Epoch time: 205.41 s\n",
      "2024-07-22 21:57:53.947281: Yayy! New best EMA pseudo Dice: 0.6790000200271606\n",
      "2024-07-22 21:57:56.883493: Training done.\n",
      "2024-07-22 21:57:56.893948: Using splits from existing split file: ./work_dir/nnUNet_preprocessed/Dataset009_Task09_Spleen/splits_final.json\n",
      "2024-07-22 21:57:56.894156: The split file contains 5 splits.\n",
      "2024-07-22 21:57:56.894228: Desired fold for training: 0\n",
      "2024-07-22 21:57:56.894295: This split has 32 training and 9 validation cases.\n",
      "2024-07-22 21:57:56.894436: predicting case_0\n",
      "2024-07-22 21:57:56.895098: case_0, shape torch.Size([1, 280, 520, 520]), rank 0\n",
      "2024-07-22 22:00:40.530753: predicting case_10\n",
      "2024-07-22 22:00:40.545273: case_10, shape torch.Size([1, 297, 497, 497]), rank 0\n",
      "2024-07-22 22:03:08.903142: predicting case_11\n",
      "2024-07-22 22:03:08.915802: case_11, shape torch.Size([1, 287, 562, 562]), rank 0\n",
      "2024-07-22 22:06:10.180272: predicting case_13\n",
      "2024-07-22 22:06:10.197548: case_13, shape torch.Size([1, 305, 512, 512]), rank 0\n",
      "2024-07-22 22:08:38.507277: predicting case_26\n",
      "2024-07-22 22:08:38.523466: case_26, shape torch.Size([1, 303, 512, 512]), rank 0\n",
      "2024-07-22 22:11:08.715077: predicting case_28\n",
      "2024-07-22 22:11:08.732527: case_28, shape torch.Size([1, 156, 614, 614]), rank 0\n",
      "2024-07-22 22:12:39.785306: predicting case_31\n",
      "2024-07-22 22:12:39.797100: case_31, shape torch.Size([1, 325, 583, 583]), rank 0\n",
      "2024-07-22 22:16:26.921960: predicting case_34\n",
      "2024-07-22 22:16:26.941787: case_34, shape torch.Size([1, 144, 451, 451]), rank 0\n",
      "2024-07-22 22:17:12.746280: predicting case_38\n",
      "2024-07-22 22:17:12.753967: case_38, shape torch.Size([1, 157, 487, 487]), rank 0\n",
      "^C\n",
      "Process SpawnPoolWorker-63:\n",
      "Process SpawnPoolWorker-57:\n",
      "Process SpawnPoolWorker-58:\n",
      "Process SpawnPoolWorker-62:\n",
      "Process SpawnPoolWorker-64:\n",
      "Process SpawnPoolWorker-61:\n",
      "Process SpawnPoolWorker-60:\n",
      "Process SpawnPoolWorker-59:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mark/miniforge3/envs/nnunet/lib/python3.11/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m monai.apps.nnunet nnUNetV2Runner train --input_config \"./input.yaml\" --trainer_class_name nnUNetTrainer_1epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run nnU-Net modules using ```nnUNetV2Runner```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```nnUNetV2Runner``` offers the one-stop API to execute the pipeline, as well as the APIs to access the underlying components of nnU-Net V2. Below is the command for different components.\n",
    "\n",
    "```bash\n",
    "## [component] convert dataset\n",
    "python -m monai.apps.nnunet nnUNetV2Runner convert_dataset --input_config \"./input.yaml\"\n",
    "\n",
    "## [component] experiment planning and data pre-processing\n",
    "python -m monai.apps.nnunet nnUNetV2Runner plan_and_process --input_config \"./input.yaml\"\n",
    "\n",
    "## [component] use all available GPU(s) to train all 20 models\n",
    "python -m monai.apps.nnunet nnUNetV2Runner train --input_config \"./input.yaml\"\n",
    "\n",
    "## [component] use all available GPU(s) to train a single model\n",
    "python -m monai.apps.nnunet nnUNetV2Runner train_single_model --input_config \"./input.yaml\" \\\n",
    "    --config \"3d_fullres\" \\\n",
    "    --fold 0\n",
    "\n",
    "## [component] distributed training of 20 models utilizing specified GPU devices 0 and 1\n",
    "python -m monai.apps.nnunet nnUNetV2Runner train --input_config \"./input.yaml\" --gpu_id_for_all 0,1\n",
    "\n",
    "## [component] find best configuration\n",
    "python -m monai.apps.nnunet nnUNetV2Runner find_best_configuration --input_config \"./input.yaml\"\n",
    "\n",
    "## [component] predict, ensemble, and postprocessing\n",
    "python -m monai.apps.nnunet nnUNetV2Runner predict_ensemble_postprocessing --input_config \"./input.yaml\"\n",
    "\n",
    "## [component] predict only\n",
    "python -m monai.apps.nnunet nnUNetV2Runner predict_ensemble_postprocessing --input_config \"./input.yaml\" \\\n",
    "\t--run_ensemble false --run_postprocessing false\n",
    "\n",
    "## [component] ensemble only\n",
    "python -m monai.apps.nnunet nnUNetV2Runner predict_ensemble_postprocessing --input_config \"./input.yaml\" \\\n",
    "\t--run_predict false --run_postprocessing false\n",
    "\n",
    "## [component] post-processing only\n",
    "python -m monai.apps.nnunet nnUNetV2Runner predict_ensemble_postprocessing --input_config \"./input.yaml\" \\\n",
    "\t--run_predict false --run_ensemble false\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For utilizing PyTorch DDP in multi-GPU training, the subsequent command is offered to facilitate the training of a singlular model on a specific fold:\n",
    "\n",
    "```bash\n",
    "## [component] multi-gpu training for a single model\n",
    "python -m monai.apps.nnunet nnUNetV2Runner train_single_model --input_config \"./input.yaml\" \\\n",
    "    --config \"3d_fullres\" \\\n",
    "    --fold 0 \\\n",
    "    --gpu_id 0,1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We offer an alternative API for constructing datasets from [MSD challenge](http://medicaldecathlon.com/) to meet requirements of nnU-Net, as reference in the provided [link](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/dataset_format.md#how-to-use-decathlon-datasets).\n",
    "\n",
    "```bash\n",
    "## [component] converting msd datasets\n",
    "python -m monai.apps.nnunet nnUNetV2Runner convert_msd_dataset --input_config \"./input.yaml\" --data_dir \"/workspace/data/Task09_Spleen\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nnunet)",
   "language": "python",
   "name": "nnunet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
